{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e8ee855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "clean_data = \"../data/clean_modeling_data.csv\"\n",
    "data = pd.read_csv(clean_data)\n",
    "docs = data[\"comment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5492c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dinyad/anaconda3/envs/bertopic-env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'I have a problem with my iphone that needs to be resolved asap!',\n",
       " 'labels': ['urgent', 'phone', 'computer', 'not urgent', 'tablet'],\n",
       " 'scores': [0.5227585434913635,\n",
       "  0.4581397473812103,\n",
       "  0.014264755882322788,\n",
       "  0.0026849983260035515,\n",
       "  0.0021520687732845545]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(model=\"facebook/bart-large-mnli\")\n",
    "pipe(\"I have a problem with my iphone that needs to be resolved asap!\",\n",
    "    candidate_labels=[\"urgent\", \"not urgent\", \"phone\", \"tablet\", \"computer\"],\n",
    ")\n",
    "# output\n",
    "#>>> {'sequence': 'I have a problem with my iphone that needs to be resolved asap!!', 'labels': ['urgent', 'phone', 'computer', 'not urgent', 'tablet'], 'scores': [0.504, 0.479, 0.013, 0.003, 0.002]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd59ceaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"So it appears Tesla found a bug in their app after watching this video that accidentally counted all production and usage totals as DOUBLE their actual numbers. Doesn't affect my payback timeline calculations, but it does make more sense that I was seeing ~4000kWh of production in a month, not 8000 ðŸ¤“\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [\"Advisor\", \"Seeker\"]\n",
    "\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b89cad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'Yes, you cannot produce 350 kWh of energy in a day with a ~40kW panel array. At your latitude, four times kWp in the best case scenario makes more sense.',\n",
       " 'labels': ['Advisor', 'Seeker'],\n",
       " 'scores': [0.5359474420547485, 0.4640524983406067]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(docs[3],labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19810b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying comments...\n",
      "\n",
      "Total classified comments: 1000\n",
      "Advisor: 680 (68.0%)\n",
      "Seeker: 320 (32.0%)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def classify_comment(comment):\n",
    "    result = pipe(comment, labels)\n",
    "    return result['labels'][0]  # Top label (most likely role)\n",
    "\n",
    "# Vectorize the function\n",
    "vectorized_classifier = np.vectorize(classify_comment)\n",
    "\n",
    "# Apply classification to the first 100 comments\n",
    "print(\"Classifying comments...\")\n",
    "\n",
    "sampled_docs = random.sample(list(docs), 1000)\n",
    "predicted_roles = vectorized_classifier(np.array(sampled_docs))\n",
    "\n",
    "# Count results\n",
    "unique, counts = np.unique(predicted_roles, return_counts=True)\n",
    "role_stats = dict(zip(unique, counts))\n",
    "\n",
    "# Compute percentages\n",
    "total = sum(counts)\n",
    "advisor_pct = (role_stats.get(\"Advisor\", 0) / total) * 100\n",
    "seeker_pct = (role_stats.get(\"Seeker\", 0) / total) * 100\n",
    "\n",
    "# Display\n",
    "print(f\"\\nTotal classified comments: {total}\")\n",
    "print(f\"Advisor: {role_stats.get('Advisor', 0)} ({advisor_pct:.1f}%)\")\n",
    "print(f\"Seeker: {role_stats.get('Seeker', 0)} ({seeker_pct:.1f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bertopic-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
